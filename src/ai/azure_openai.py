"""Azure OpenAI ç­–ç•¥å®žçŽ° â€” Strategy æ¨¡å¼çš„å…·ä½“ç­–ç•¥.

ä½¿ç”¨ Azure OpenAI GPT æ¨¡åž‹ç”Ÿæˆè§†é¢‘æ€»ç»“å’Œå›žç­”ã€‚
"""

from __future__ import annotations

import logging

from openai import APIConnectionError, APITimeoutError, AsyncAzureOpenAI
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from src.ai.base import AIProvider

logger = logging.getLogger(__name__)

_SYSTEM_PROMPT_SUMMARY = """ä½ æ˜¯ä¸€ä¸ª Bç«™è§†é¢‘å†…å®¹æ€»ç»“åŠ©æ‰‹ã€‚
ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªè§†é¢‘çš„æ ‡é¢˜ã€ç®€ä»‹å’Œå­—å¹•å†…å®¹ï¼Œè¯·ä½ ç”Ÿæˆä¸€ä¸ªç®€æ´æ˜Žäº†çš„æ€»ç»“ã€‚

ã€æ ¼å¼è¦æ±‚ã€‘- è¿™æ˜¯Bç«™è¯„è®ºåŒºï¼Œä¸æ”¯æŒä»»ä½• Markdown è¯­æ³•ï¼
- ç¦æ­¢ä½¿ç”¨ **ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ã€- åˆ—è¡¨ ç­‰ Markdown æ ¼å¼
- ç”¨æ•°å­—åºå·ï¼ˆ1. 2. 3.ï¼‰æˆ– emojiï¼ˆðŸ“ŒðŸ”¹â–¸ï¼‰æ¥ç»„ç»‡å†…å®¹
- æ¯ä¸ªè¦ç‚¹ç‹¬å ä¸€è¡Œï¼Œä¿æŒç®€æ´
- é€‚åˆæ‰‹æœºç«¯é˜…è¯»ï¼Œé¿å…å¤§æ®µæ–‡å­—

ã€å†…å®¹è¦æ±‚ã€‘
- æ€»ç»“æŽ§åˆ¶åœ¨ 250 å­—ä»¥å†…
- æç‚¼ 3-5 ä¸ªæ ¸å¿ƒè¦ç‚¹
- è¯­æ°”å‹å¥½è‡ªç„¶ï¼Œåƒçƒ­å¿ƒçš„ Bç«™ç”¨æˆ·
- ä¸è¦æåŠ"å­—å¹•"ã€"æ ¹æ®å­—å¹•"ç­‰è¯æ±‡"""

_SYSTEM_PROMPT_QA = """ä½ æ˜¯ä¸€ä¸ª Bç«™è§†é¢‘å†…å®¹é—®ç­”åŠ©æ‰‹ã€‚
ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªè§†é¢‘çš„æ ‡é¢˜ã€ç®€ä»‹å’Œå­—å¹•å†…å®¹ï¼Œä»¥åŠä¸€ä¸ªå…·ä½“çš„é—®é¢˜ã€‚

ã€æ ¼å¼è¦æ±‚ã€‘- è¿™æ˜¯Bç«™è¯„è®ºåŒºï¼Œä¸æ”¯æŒä»»ä½• Markdown è¯­æ³•ï¼
- ç¦æ­¢ä½¿ç”¨ **ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ ç­‰ Markdown æ ¼å¼
- ç›´æŽ¥ç”¨çº¯æ–‡æœ¬å›žç­”ï¼Œå¯ç”¨ emoji ç‚¹ç¼€
- é€‚åˆæ‰‹æœºç«¯é˜…è¯»

ã€å†…å®¹è¦æ±‚ã€‘
- å›žç­”æŽ§åˆ¶åœ¨ 250 å­—ä»¥å†…
- å¦‚æžœè§†é¢‘å†…å®¹ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®žè¯´æ˜Ž
- è¯­æ°”å‹å¥½è‡ªç„¶ï¼Œåƒçƒ­å¿ƒçš„ Bç«™ç”¨æˆ·
- ä¸è¦æåŠ"å­—å¹•"ã€"æ ¹æ®å­—å¹•"ç­‰è¯æ±‡"""


class AzureOpenAIProvider(AIProvider):
    """Azure OpenAI å…·ä½“ç­–ç•¥.

    å°è£… Azure OpenAI API è°ƒç”¨ï¼Œå®žçŽ° AIProvider ç­–ç•¥æŽ¥å£ã€‚
    """

    def __init__(
        self,
        endpoint: str,
        api_key: str,
        deployment: str,
        api_version: str = "2025-01-01-preview",
    ) -> None:
        self._deployment = deployment
        self._client = AsyncAzureOpenAI(
            azure_endpoint=endpoint,
            api_key=api_key,
            api_version=api_version,
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(min=2, max=15),
        retry=retry_if_exception_type((APIConnectionError, APITimeoutError)),
    )
    async def summarize_video(self, video_context: str) -> str:
        """è°ƒç”¨ Azure OpenAI ç”Ÿæˆè§†é¢‘æ€»ç»“."""
        logger.debug("è°ƒç”¨ AI ç”Ÿæˆæ€»ç»“, ä¸Šä¸‹æ–‡é•¿åº¦: %d", len(video_context))

        response = await self._client.chat.completions.create(
            model=self._deployment,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT_SUMMARY},
                {"role": "user", "content": video_context},
            ],
            max_completion_tokens=800,
            temperature=0.7,
        )

        result = response.choices[0].message.content or ""
        logger.info(
            "AI æ€»ç»“ç”Ÿæˆå®Œæˆ, tokens: prompt=%s completion=%s",
            response.usage.prompt_tokens if response.usage else "?",
            response.usage.completion_tokens if response.usage else "?",
        )
        return result.strip()

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(min=2, max=15),
        retry=retry_if_exception_type((APIConnectionError, APITimeoutError)),
    )
    async def answer_question(
        self, video_context: str, question: str
    ) -> str:
        """è°ƒç”¨ Azure OpenAI å›žç­”å…³äºŽè§†é¢‘çš„é—®é¢˜."""
        logger.debug("è°ƒç”¨ AI å›žç­”é—®é¢˜: %s", question[:50])

        user_message = f"{video_context}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}"

        response = await self._client.chat.completions.create(
            model=self._deployment,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT_QA},
                {"role": "user", "content": user_message},
            ],
            max_completion_tokens=800,
            temperature=0.7,
        )

        result = response.choices[0].message.content or ""
        logger.info(
            "AI å›žç­”ç”Ÿæˆå®Œæˆ, tokens: prompt=%s completion=%s",
            response.usage.prompt_tokens if response.usage else "?",
            response.usage.completion_tokens if response.usage else "?",
        )
        return result.strip()

    async def close(self) -> None:
        """å…³é—­ Azure OpenAI å®¢æˆ·ç«¯."""
        await self._client.close()
